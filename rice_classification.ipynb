{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6825b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98218d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"device using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08055440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
      "0   1  4537        92.229316        64.012769      0.719916        4677   \n",
      "1   2  2872        74.691881        51.400454      0.725553        3015   \n",
      "2   3  3048        76.293164        52.043491      0.731211        3132   \n",
      "3   4  3073        77.033628        51.928487      0.738639        3157   \n",
      "4   5  3693        85.124785        56.374021      0.749282        3802   \n",
      "\n",
      "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
      "0      76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
      "1      60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
      "2      62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
      "3      62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
      "4      68.571668  0.769375    230.332   0.874743      1.510000      1  \n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"riceClassification.csv\")\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4748d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 0\n",
      "Area               0\n",
      "MajorAxisLength    0\n",
      "MinorAxisLength    0\n",
      "Eccentricity       0\n",
      "ConvexArea         0\n",
      "EquivDiameter      0\n",
      "Extent             0\n",
      "Perimeter          0\n",
      "Roundness          0\n",
      "AspectRation       0\n",
      "Class              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fe138",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c422371",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "250a2726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18185, 11)\n"
     ]
    }
   ],
   "source": [
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "Class\n",
      "1    9985\n",
      "0    8200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_df[\"Class\"].unique())\n",
    "print(data_df[\"Class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9316405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization needed(a pre-processing technique):\n",
    "# this is done to make the larger numerical values to be in a commaon range of value.\n",
    "# we take each column and each value is divided by the maximum value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in data_df.columns:\n",
    "    data_df[cols] = data_df[cols] / data_df[cols].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc56256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
      "0  0.444368         0.503404         0.775435      0.744658    0.424873   \n",
      "1  0.281293         0.407681         0.622653      0.750489    0.273892   \n",
      "2  0.298531         0.416421         0.630442      0.756341    0.284520   \n",
      "3  0.300979         0.420463         0.629049      0.764024    0.286791   \n",
      "4  0.361704         0.464626         0.682901      0.775033    0.345385   \n",
      "\n",
      "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
      "0       0.666610  0.741661   0.537029   0.844997      0.368316    1.0  \n",
      "1       0.530370  0.804230   0.409661   0.919215      0.371471    1.0  \n",
      "2       0.546380  0.856278   0.412994   0.959862      0.374747    1.0  \n",
      "3       0.548616  0.883772   0.414262   0.961818      0.379222    1.0  \n",
      "4       0.601418  0.867808   0.452954   0.966836      0.386007    1.0  \n"
     ]
    }
   ],
   "source": [
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2c48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data_df.iloc[:,:-1])\n",
    "Y=np.array(data_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe238e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed1c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,X_val,y_test,y_val=train_test_split(X_test,y_test,test_size=0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc5e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e84968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X=torch.tensor(X,dtype=torch.float32).to(device)\n",
    "        self.Y=torch.tensor(Y,dtype=torch.float32).to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c3e92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=dataset(X_train,y_train)\n",
    "validation_data=dataset(X_val,y_val)\n",
    "test_data=dataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c07999ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader=DataLoader(training_data,batch_size=8,shuffle=True)\n",
    "validation_dataloader=DataLoader(validation_data,batch_size=8,shuffle=True)   \n",
    "test_dataloader=DataLoader(test_data,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4089bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6209, 0.8163, 0.6639, 0.9624, 0.5888, 0.7879, 0.5690, 0.6691, 0.7605,\n",
      "         0.6976],\n",
      "        [0.5654, 0.7849, 0.6284, 0.9647, 0.5362, 0.7519, 0.7571, 0.6402, 0.7565,\n",
      "         0.7087],\n",
      "        [0.6981, 0.8756, 0.6947, 0.9660, 0.6656, 0.8355, 0.7259, 0.7164, 0.7460,\n",
      "         0.7151],\n",
      "        [0.8767, 0.9031, 0.8439, 0.9382, 0.8323, 0.9363, 0.6193, 0.7697, 0.8116,\n",
      "         0.6071],\n",
      "        [0.6259, 0.8520, 0.6470, 0.9719, 0.5989, 0.7911, 0.5363, 0.6859, 0.7295,\n",
      "         0.7471],\n",
      "        [0.6135, 0.7597, 0.7081, 0.9387, 0.5902, 0.7833, 0.6444, 0.6503, 0.7955,\n",
      "         0.6087],\n",
      "        [0.6751, 0.8940, 0.6653, 0.9745, 0.6434, 0.8217, 0.5382, 0.7165, 0.7212,\n",
      "         0.7623],\n",
      "        [0.5616, 0.8708, 0.5636, 0.9894, 0.5351, 0.7494, 0.7274, 0.6835, 0.6593,\n",
      "         0.8766]], device='cuda:0')\n",
      "==========\n",
      "tensor([1., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for x,y in training_dataloader:\n",
    "    print(x)\n",
    "    print(\"==========\")\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f85c0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.input_layer=nn.Linear(X.shape[1],20)\n",
    "        self.linear=nn.Linear(20,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x=self.input_layer(x)\n",
    "        x=self.linear(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model=Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31485b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 20]                  220\n",
      "├─Linear: 1-2                            [-1, 1]                   21\n",
      "├─Sigmoid: 1-3                           [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 20]                  220\n",
       "├─Linear: 1-2                            [-1, 1]                   21\n",
       "├─Sigmoid: 1-3                           [-1, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 241\n",
       "Trainable params: 241\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,(X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b339f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "532f6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.1072\n",
      "Validation Loss: 0.0197\n",
      "Training Accuracy: 98.5231\n",
      "Validation Accuracy: 98.607\n",
      "=====================================\n",
      "Epoch 2/10\n",
      "Training Loss: 0.0747\n",
      "Validation Loss: 0.0178\n",
      "Training Accuracy: 98.6723\n",
      "Validation Accuracy: 98.607\n",
      "=====================================\n",
      "Epoch 3/10\n",
      "Training Loss: 0.0667\n",
      "Validation Loss: 0.0173\n",
      "Training Accuracy: 98.688\n",
      "Validation Accuracy: 98.2771\n",
      "=====================================\n",
      "Epoch 4/10\n",
      "Training Loss: 0.0639\n",
      "Validation Loss: 0.0162\n",
      "Training Accuracy: 98.6802\n",
      "Validation Accuracy: 98.5704\n",
      "=====================================\n",
      "Epoch 5/10\n",
      "Training Loss: 0.0634\n",
      "Validation Loss: 0.0161\n",
      "Training Accuracy: 98.633\n",
      "Validation Accuracy: 98.5337\n",
      "=====================================\n",
      "Epoch 6/10\n",
      "Training Loss: 0.0628\n",
      "Validation Loss: 0.0165\n",
      "Training Accuracy: 98.6645\n",
      "Validation Accuracy: 98.717\n",
      "=====================================\n",
      "Epoch 7/10\n",
      "Training Loss: 0.0627\n",
      "Validation Loss: 0.0163\n",
      "Training Accuracy: 98.5781\n",
      "Validation Accuracy: 98.6437\n",
      "=====================================\n",
      "Epoch 8/10\n",
      "Training Loss: 0.0622\n",
      "Validation Loss: 0.0162\n",
      "Training Accuracy: 98.7116\n",
      "Validation Accuracy: 98.717\n",
      "=====================================\n",
      "Epoch 9/10\n",
      "Training Loss: 0.0624\n",
      "Validation Loss: 0.0162\n",
      "Training Accuracy: 98.743\n",
      "Validation Accuracy: 98.717\n",
      "=====================================\n",
      "Epoch 10/10\n",
      "Training Loss: 0.0623\n",
      "Validation Loss: 0.0183\n",
      "Training Accuracy: 98.688\n",
      "Validation Accuracy: 98.607\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "total_loss_train_plot=[]\n",
    "total_loss_valid_plot=[]\n",
    "total_acc_train_plot=[]\n",
    "total_acc_valid_plot=[]\n",
    "\n",
    "epochs=10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss_train=0\n",
    "    total_loss_valid=0\n",
    "    total_acc_train=0\n",
    "    total_acc_valid=0\n",
    "    \n",
    "    for data in training_dataloader:\n",
    "        input,labels=data\n",
    "        predictions=model(input).squeeze(1)\n",
    "        batch_loss=criterion(predictions,labels)\n",
    "        total_loss_train+=batch_loss.item()\n",
    "        acc=(predictions.round()==labels).sum().item()\n",
    "        total_acc_train+=acc\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in validation_dataloader:\n",
    "            inputs,labels=data\n",
    "            predictions=model(inputs).squeeze(1)\n",
    "            batch_loss=criterion(predictions,labels)\n",
    "            total_loss_valid+=batch_loss.item()\n",
    "            acc=(predictions.round()==labels).sum().item()\n",
    "            total_acc_valid+=acc\n",
    "            \n",
    "    total_loss_train_plot.append(round(total_loss_train/1000,4))\n",
    "    total_loss_valid_plot.append(round(total_loss_valid/1000,4))\n",
    "    \n",
    "    total_acc_train_plot.append(round(total_acc_train/training_data.__len__() * 100,4))\n",
    "    total_acc_valid_plot.append(round(total_acc_valid/validation_data.__len__() * 100,4))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Training Loss: {round(total_loss_train/1000,4)}\")\n",
    "    print(f\"Validation Loss: {round(total_loss_valid/1000,4)}\")\n",
    "    print(f\"Training Accuracy: {round(total_acc_train/training_data.__len__() * 100,4)}\")\n",
    "    print(f\"Validation Accuracy: {round(total_acc_valid/validation_data.__len__() * 100,4)}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e4c07b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.2405 Loss:  0.0173\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss_test=0\n",
    "    total_acc_test=0\n",
    "    for data in test_dataloader:\n",
    "        inputs,labels=data\n",
    "        predictions=model(inputs).squeeze(1)\n",
    "        batch_loss=criterion(predictions,labels)\n",
    "        total_loss_test+=batch_loss.item()\n",
    "        acc=(predictions.round()==labels).sum().item()\n",
    "        total_acc_test+=acc\n",
    "        \n",
    "print(\"Accuracy: \",round(total_acc_test/test_data.__len__() * 100,4),\"Loss: \",round(total_loss_test/1000,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
